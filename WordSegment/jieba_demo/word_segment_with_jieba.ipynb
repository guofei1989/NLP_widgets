{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 中文分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持三种分词模式： <br>\n",
    "精确模式，试图将句子最精确地切开，适合文本分析； <br>\n",
    "全模式，把句子中所有的可以成词的词语都扫描处理，速度非常快，但是不能解决歧义； <br>\n",
    "搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于引擎分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'从头开始/梳理/NLP/的/知识/体系'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "jieba.cut(sentence=, cut_all=, HMM=)\n",
    "sentence: 分词语句\n",
    "cut_all: True/False, 是否采用全模式， 默认False\n",
    "HMM: 是否采用HMM模型\n",
    "\n",
    "RETURN: 生成器\n",
    "\"\"\"\n",
    "sent1 = \"从头开始梳理NLP的知识体系\"\n",
    "'/'.join(jieba.cut(sent1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'从头/从头开始/开始/梳理/NLP/的/知识/识体/体系'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut全模式分词\n",
    "'/'.join(jieba.cut(sent1, cut_all=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'从头/开始/从头开始/梳理/NLP/的/知识/体系'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cut_for_search  搜索引擎模式 分词\n",
    "参数同cut\n",
    "\"\"\"\n",
    "'/'.join(jieba.cut_for_search(sent1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['从头开始', '梳理', 'NLP', '的', '知识', '体系']\n",
      "['从头', '开始', '从头开始', '梳理', 'NLP', '的', '知识', '体系']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "lcut和lcut_for_search分别作为cut和cut_for_search的衍生，直接获取列表对象\n",
    "\"\"\"\n",
    "print(jieba.lcut(sent1))\n",
    "print(jieba.lcut_for_search(sent1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 添加自定义词或词典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过添加自定义词或词典，以便对jieba词库里没有的词进行切分 <br>\n",
    "jieba.add_word: 添加词<br>jieba.del_word: 删除词<br>jieba.initialize: 初始化字典<br> jieba.set_dictionary: 设置词典<br>  jieba.load_userdict: 添加词典<br>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'通过/活检/和/免疫组化/，/基因/分析/等/多项/检查/，/医生/诊断/为/滤泡/淋巴瘤'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于专业或非常见词，需自定义词\n",
    "'/'.join(jieba.cut(\"通过活检和免疫组化，基因分析等多项检查，医生诊断为滤泡淋巴瘤\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'通过/活检/和/免疫组化/，/基因分析/等/多项/检查/，/医生/诊断/为/滤泡/淋巴瘤'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "jieba.add_word(word=, freq=, tag=)\n",
    "word: 需要添加的词\n",
    "freq: 词频\n",
    "tag: 词性\n",
    "freq和tag非必填\n",
    "\"\"\"\n",
    "jieba.add_word('基因分析')\n",
    "'/'.join(jieba.cut(\"通过活检和免疫组化，基因分析等多项检查，医生诊断为滤泡淋巴瘤\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'通过/活检/和/免疫组化/，/基因分析/等/多项/检查/，/医生/诊断/为/滤泡淋巴瘤'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "jieba.load_dictionary(f)\n",
    "f: 字典地址或文件指针, 字典文档格式每行为  word \\s frequency \\s tag,  frquency和tag非必须\n",
    "\"\"\"\n",
    "jieba.initialize()\n",
    "jieba.load_userdict('./user_dict.txt')\n",
    "'/'.join(jieba.cut(\"通过活检和免疫组化，基因分析等多项检查，医生诊断为滤泡淋巴瘤\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 更改词频"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jieba的内部算法中进行DAG最大概率搜索时，会统计词频<br>\n",
    "jieba.suggest_freq(segment, tune=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case1: 强行拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中将: 763 , 中: 243191\n"
     ]
    }
   ],
   "source": [
    "# 中将的频率\n",
    "print(\"中将: {} , 中: {}\".format(jieba.get_FREQ(\"中将\"), jieba.get_FREQ(\"中\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['如果', '放到', 'post', '中将', '出错']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.lcut(\"如果放到post中将出错\", HMM=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['如果', '放到', 'post', '中', '将', '出错']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq((\"中\", \"将\"), True)   # tune设为True使其生效\n",
    "jieba.lcut(\"如果放到post中将出错\", HMM=False)    # 注意HMM需设为False，否则会影响分词结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case2：强行组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['「', '台', '中', '」', '发生', '了', '龙卷风']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.lcut(\"「台中」发生了龙卷风\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['「', '台中', '」', '发生', '了', '龙卷风']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq(\"台中\", True)   # tune设为True使其生效, S\n",
    "jieba.lcut(\"「台中」发生了龙卷风\", HMM=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case3: 识别【带空格的词】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/rk/nnl9yhm55kb6325ckffkn6hw0000gn/T/jieba.cache\n",
      "Loading model cost 0.676 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修改前： ['Blade', ' ', 'Master', '疾风', '刺杀', 'Archmage']\n",
      "修改后： ['Blade Master', '疾风', '刺杀', 'Archmage']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sentence = 'Blade Master疾风刺杀Archmage'\n",
    "jieba.add_word('Blade Master')  # 添词\n",
    "print('修改前：', jieba.lcut(sentence))\n",
    "jieba.re_han_default = re.compile('(.+)', re.U)  # 修改格式\n",
    "print('修改后：', jieba.lcut(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 停用词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jieba中没有直接的停用词接口，需手动进行加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r').readlines()]\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_seg(sentence, stopwords):\n",
    "    seg = []\n",
    "    for word in jieba.cut(sentence=sentence):\n",
    "        if word not in stopwords:\n",
    "            seg.append(word)\n",
    "    return seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今天', '下', '了', '一场', '大雨', '，', '好多', '人', '都', '被', '淋湿', '了']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 增加停用词前\n",
    "jieba.lcut(\"今天下了一场大雨，好多人都被淋湿了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今天', '一场', '大雨', '好多', '淋湿']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 增加停用词后\n",
    "sentence_seg(\"今天下了一场大雨，好多人都被淋湿了\", stopwordslist('../StopWords/stop_words_1.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分词同时定位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word:今天天气, start:0, end:4\n",
      "word:不错, start:4, end:6\n",
      "------------------------------\n",
      "word:今天, start:0, end:2\n",
      "word:天天, start:1, end:3\n",
      "word:天气, start:2, end:4\n",
      "word:今天天气, start:0, end:4\n",
      "word:不错, start:4, end:6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "jieba.tokenize(unicode_sentence, mode=\"default\", HMM=True)\n",
    "mode: \"default\" 或 \"search\"（类似于cut_for_search）\n",
    "其内部调用了jieba.cut命令\n",
    "\"\"\"\n",
    "for item in jieba.tokenize(\"今天天气不错\"):\n",
    "    print(\"word:{}, start:{}, end:{}\".format(item[0], item[1], item[2]))\n",
    "print(\"-\"*30)\n",
    "for item in jieba.tokenize(\"今天天气不错\",mode=\"search\"):\n",
    "    print(\"word:{}, start:{}, end:{}\".format(item[0], item[1], item[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/rk/nnl9yhm55kb6325ckffkn6hw0000gn/T/jieba.cache\n",
      "Loading model cost 0.790 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['今天天气', '不错']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tokenizer = jieba.Tokenizer(dictionary=)\n",
    "通过不同的字典定义不同的分词器进行分词\n",
    "\"\"\"\n",
    "tokenizer = jieba.Tokenizer()\n",
    "tokenizer.lcut(\"今天天气不错\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 并行分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沙瑞金赞叹易学习的胸怀，是金山的百姓有福，可是这件事对李达康的触动很大。易学习又回忆起他们三人分开的前一晚，大家一起喝酒话别，易学习被降职到道口县当县长，王大路下海经商，李达康连连赔礼道歉，觉得对不起大家，他最对不起的是王大路，就和易学习一起给王大路凑了5万块钱，王大路自己东挪西撮了5万块，开始下海经商。没想到后来王大路竟然做得风生水起。沙瑞金觉得他们三人，在困难时期还能以沫相助，很不容易。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "with open('./data/cutdata', 'r', encoding='utf-8') as f:\n",
    "    sent2 = f.read()\n",
    "print(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.318092346191406e-05\n"
     ]
    }
   ],
   "source": [
    "# 不并行分词\n",
    "t1 = time.time()\n",
    "jieba.cut(sent2)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001399517059326172\n"
     ]
    }
   ],
   "source": [
    "# 并行分词\n",
    "jieba.enable_parallel(4)\n",
    "t1 = time.time()\n",
    "jieba.cut(sent2)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
